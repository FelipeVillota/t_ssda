---
title: "t_ssda"
output: html_document
date: "2023-05-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Setting the working directory 

```{r}
setwd("C:/Users/lu2336vi/Work Folders/Desktop/t_ssda/aa_data")

getwd()
```

## 2. Loading initial packages

```{r}
library(stringr)
library(forcats)
library(gutenbergr)
library(tidyverse)
library(tidytext)
library(tm)
library(textdata)
library(psych)
library(skimr)
library(wordcloud2)
library(tidyr)
library(lifecycle)
library(scales)
library(Amelia)
library(igraph)
library(ggplot2)
```

## 3. Loading the raw AA database

```{r}
raw_fb_data <- read.csv("C:/Users/lu2336vi/Work Folders/Desktop/t_ssda/aa_data/all_comments.csv")
```

## **4. Exploratory data analysis (EDA) of the raw database and its variables**

```{r}
str(raw_fb_data) # 6,217,154 obs. of  38 variables

attributes(raw_fb_data)

# Column names
colnames(raw_fb_data)

head(raw_fb_data)


length(unique(raw_fb_data$page_name)) # 565 unique pages
length(unique(raw_fb_data$category)) # 82 different page categories
length(unique(raw_fb_data$id_post)) # 72,441 unique posts
length(unique(raw_fb_data$id_comment)) # 6,217,154 unique comments
length(unique(raw_fb_data$location_json)) # 336 unique page locations


# Checking for missing values

any(is.na(raw_fb_data)) # TRUE
sum(is.na(raw_fb_data)) # 11,686,900 cases in total
colSums(is.na(raw_fb_data)) # distribution of missing values by variable 
colnames(raw_fb_data)[colSums(is.na(raw_fb_data)) > 0] # NAs in 8 var.: "score_0_disagreement", "score_1_disagreement", "score_0_antagonism", "score_1_antagonism","disagreement","antagonism"           "comment_count","page_like_count"



# Time span of posts
min(raw_fb_data$created_time_post) # Earliest = 2016-01-03 23:01:49
max(raw_fb_data$created_time_post) # Latest = 2022-06-24 13:47:14

# Time span of comments
min(raw_fb_data$created_time_comment) # Earliest = 2016-01-04 00:28:11
max(raw_fb_data$created_time_comment) # Latest = 2022-10-23 06:57:17

# Reactions on posts

min_max_table_rp <- raw_fb_data %>%
  summarize(
    love_post_min = min(love_post),
    love_post_max = max(love_post),
    like_post_min = min(like_post),
    like_post_max = max(like_post),
    angry_post_min = min(angry_post),
    angry_post_max = max(angry_post),
    sad_post_min = min(sad_post),
    sad_post_max = max(sad_post),
    haha_post_min = min(haha_post),
    haha_post_max = max(haha_post),
    wow_post_min = min(wow_post),
    wow_post_max = max(wow_post),
    shares_min = min(shares),
    shares_max = max(shares)
  )

min_max_table_rp


# Reactions on comments

min_max_table_rc <- raw_fb_data %>%
  summarize(
    love_comment_min = min(love_comment),
    love_comment_max = max(love_comment),
    like_comment_min = min(like_comment),
    like_comment_max = max(like_comment),
    angry_comment_min = min(angry_comment),
    angry_comment_max = max(angry_comment),
    sad_comment_min = min(sad_comment),
    sad_comment_max = max(sad_comment),
    haha_comment_min = min(haha_comment),
    haha_comment_max = max(haha_comment),
    wow_comment_min = min(wow_comment),
    wow_comment_max = max(wow_comment)
  )

min_max_table_rc


# The Facebook public fan page with more likes = Noticias Caracol with 6,395,004 likes
max_row <- raw_fb_data[which.max(raw_fb_data$page_like_count), ]
max_page_name <- max_row$page_name
max_page_like_count <- max_row$page_like_count
cat("The page with the maximum page_like_count is", max_page_name, "with", max_page_like_count, "likes.")

# And the least liked page = Diego Patiño Amariles with 187 likes
min_row <- raw_fb_data[which.min(raw_fb_data$page_like_count), ]
min_page_name <- min_row$page_name
min_page_like_count <- min_row$page_like_count
cat("The page with the minimum page_like_count is", min_page_name, "with", min_page_like_count, "likes.")

# The most liked post message by a page =
# A la Nación colombiana. Al soldado, al policía, al manifestante; al Comité de Paro, al presidente Duque. Esta es mi segunda alocución sobre la situación nacional. By Gustavo Petro with 145,955 likes.
max_row_post <- raw_fb_data[which.max(raw_fb_data$like_post), ]
max_post_message <- max_row_post$post_message
max_post_like_count <- max_row_post$like_post
max_post_page_name <- max_row_post$page_name
cat("The post message with the maximum like count is", max_post_message, "with", max_post_like_count, "likes by", max_post_page_name)


# And the least liked post by a page =
# #editorialelnuevoliberal A cuidarse no solo de los contagios http://ow.ly/kECO50G8VdE By Periódico El Nuevo Liberal with 0 likes 
min_row_post <- raw_fb_data[which.min(raw_fb_data$like_post), ]
min_post_message <- min_row_post$post_message
min_post_like_count <- min_row_post$like_post
min_post_page_name <- min_row_post$page_name
cat("The post message with the minimum like count is", min_post_message, "with", min_post_like_count, "likes by", min_post_page_name)

# How many posts have 0 likes ?

raw_fb_data %>% filter(like_post == 0) %>% nrow() # Only 489 out of 72,441 

# The post by a page with the most "angry" reactions =
# El presidente Iván Duque se pronunció sobre los hechos violentos que se han presentado en las diferentes ciudades de Colombia debido al Paro Nacional. Aseguró estos se han presentado en mayor medida por parte de vándalos y que la labor de los policías es la de cuidar a los ciudadanos, por lo que se deben presentar denuncias "si llega a haber algún tipo de abuso". "En nuestra democracia se puede alzar la voz pero no se puede empuñar un arma para acallarla", añadió. By El Espectador with 58,613 angry reactions.

max_row_post_angry <- raw_fb_data[which.max(raw_fb_data$angry_post), ]
max_post_message_angry <- max_row_post_angry$post_message
max_post_angry_count_angry <- max_row_post_angry$angry_post
max_post_page_name_angry <- max_row_post_angry$page_name
cat("The post message with the maximum angry count is", max_post_message_angry,"by", max_post_page_name_angry, "with", max_post_angry_count_angry, "angry reactions.")
```

### 4.1 First data type transformations: dates and times of posts and comments

```{r}
# Both post and comments are to be changed into a "%Y-%m-%d %H:%M:%S" date format (in the Colombian time zone where they were collected)

class(raw_fb_data$created_time_comment)
class(raw_fb_data$created_time_post)

library(lubridate)

raw_tester$created_time_post <- as.Date(raw_tester$created_time_post, format = "%Y-%m-%d %H:%M:%S") 
class(raw_tester$created_time_post)
max(raw_tester$created_time_post)



raw_tester$created_time_comment <- as.POSIXct(raw_fb_data$created_time_comment, format = "%Y-%m-%d %H:%M:%S")

class(raw_tester$created_time_comment)
max(raw_tester$created_time_comment)

raw_tester1$created_time_comment 


# Histogram of number of posts and number of comments per day (2016-01-03 to 2022-06-24) 

ggplot(raw_fb_data, aes(x = created_time_post)) +
  geom_histogram(binwidth = 1, color = "black", fill = "lightblue") +
  xlab("Date") + ylab("Number of Posts") +
  ggtitle("Histogram of Number of Posts per Day")


str(raw_fb_data$created_time_post)
```

## 5. Sub-setting the database by category of interest: news media entities 

```{r}
nm_ent <- subset(raw_fb_data, 
                 category %in% c("Newspaper",
                                 "Tv-kanal",
                                 "Medier/nyheder",
                                 "TV Network",
                                 "Media/News Company",
                                 "Nyheds- og mediewebsite",
                                 "Tidsskrift",
                                 "Radiostation",
                                 "Avis",
                                 "News & media website",
                                 "Radio station",
                                 "Medie-/nyhetsbedrift",
                                 "Udsendelses- og medieproduktionsselskab",
                                 "Media/news company",
                                 "Kringkastings- og medieproduksjonsselskap",
                                 "Medier",
                                 "News & Media Website",
                                 "TV-kanal",
                                 "Radiokanal"))



length(unique(nm_ent$page_name)) # 64 unique pages
length(unique(nm_ent$category)) # 19 different page categories
length(unique(nm_ent$id_post)) # 17672 unique posts
length(unique(nm_ent$id_comment)) # 1966687 unique comments
length(unique(nm_ent$location_json)) # 52 unique page locations

```

## 6. Pre-processing of the raw data

```{r}
# Convert created_time_comment variable to POSIXct format

raw_fb_data$created_time_comment <- as.POSIXct(raw_fb_data$created_time_comment, format = "%Y-%m-%d %H:%M:%S")

# Find the earliest and latest comments

min(raw_fb_data$created_time_comment)

latest_comment <- max(raw_fb_data$created_time_comment)

min(raw_fb_data$score_0_disagreement, na.rm = T)

# Print the results

print(paste("Earliest comment:", earliest_comment))

print(paste("Latest comment:", latest_comment))

str(raw_fb_data)
```
